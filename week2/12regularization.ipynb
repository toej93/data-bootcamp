{
   "nbformat" : 4,
   "metadata" : {
      "language_info" : {
         "version" : "3.5.2",
         "nbconvert_exporter" : "python",
         "pygments_lexer" : "ipython3",
         "file_extension" : ".py",
         "codemirror_mode" : {
            "version" : 3,
            "name" : "ipython"
         },
         "name" : "python",
         "mimetype" : "text/x-python"
      },
      "org" : null,
      "kernelspec" : {
         "display_name" : "Python 3",
         "name" : "python3",
         "language" : "python"
      }
   },
   "cells" : [
      {
         "metadata" : {},
         "cell_type" : "markdown",
         "source" : [
            "Regularization imposes a penalty on the size of the coefficients in\nthe model.\n\n"
         ]
      },
      {
         "metadata" : {},
         "cell_type" : "markdown",
         "source" : [
            "## Sample data\n\n"
         ]
      },
      {
         "source" : [
            "As is our usual process, let&rsquo;s generate some fake data.  This time,\nour target is not classification but regression.\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "source" : [
            "import numpy as np\n\ndimension = 25 # should be a perfect square\nN = 1000\n\ny = np.random.normal( 0, 1, size=N )\n\nvs = np.linspace(0.01,2,dimension)\nnp.random.shuffle(vs)\n\nxs = []\nfor v in vs:\n    xs.append( np.random.normal(0,1) * np.random.normal( y, v ) )\nX = np.array( xs ).transpose()"
         ],
         "execution_count" : 1,
         "cell_type" : "code",
         "outputs" : [],
         "metadata" : {}
      },
      {
         "cell_type" : "markdown",
         "source" : [
            "What does the code above actually achieve?  As always, ****look at your\ndata****.  (Here we also see how to use `matplotlib` to produce a **grid**\nof plots which can be useful.)\n\n"
         ],
         "metadata" : {}
      },
      {
         "source" : [
            "import matplotlib.pyplot as plt\n\ngrid = int(np.sqrt(dimension))\nfor i in range(dimension):\n    plt.subplot(grid, grid, 1+i)\n    plt.scatter( y, X[:,i], s=1 )\nplt.show()"
         ],
         "execution_count" : 1,
         "cell_type" : "code",
         "outputs" : [],
         "metadata" : {}
      },
      {
         "source" : [
            "We&rsquo;ve baked in a great deal of multicollinearity!\n\nThis is also an invitation to **high-dimensional data**; our input data\nis 25 dimensional.\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "cell_type" : "markdown",
         "source" : [
            "## Linear regression\n\n"
         ],
         "metadata" : {}
      },
      {
         "cell_type" : "markdown",
         "source" : [
            "Let&rsquo;s do some linear regression.\n\n"
         ],
         "metadata" : {}
      },
      {
         "metadata" : {},
         "outputs" : [],
         "cell_type" : "code",
         "execution_count" : 1,
         "source" : [
            "from sklearn.linear_model import LinearRegression\nmodel = LinearRegression().fit( X, y )"
         ]
      },
      {
         "source" : [
            "This works well!\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "cell_type" : "code",
         "source" : [
            "model.score(X, y)"
         ],
         "execution_count" : 1,
         "outputs" : [],
         "metadata" : {}
      },
      {
         "cell_type" : "markdown",
         "source" : [
            "But it is arguably upsetting that the model coefficients are involving **all** the features of the data.\n\n"
         ],
         "metadata" : {}
      },
      {
         "outputs" : [],
         "metadata" : {},
         "cell_type" : "code",
         "source" : [
            "model.coef_"
         ],
         "execution_count" : 1
      },
      {
         "cell_type" : "markdown",
         "source" : [
            "From the plot, we can see that we can explain `y` by looking just at\n**one** feature of the data.\n\n"
         ],
         "metadata" : {}
      },
      {
         "source" : [
            "## Lasso\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "metadata" : {},
         "cell_type" : "markdown",
         "source" : [
            "Our usual linear regression involves the cost function\n$||X w - y||_2^2$.\n\nFor &ldquo;lasso&rdquo; we instead minimize the cost function\n\n${ \\frac{1}{2n}} ||X w - y||_2 ^ 2 + \\alpha ||w||_1}$.\n\nHere $\\alpha$ is the regularization parameter, and $||w||_1$ is the\nsum of the coefficients of the model.  By adding this term to the cost\nfunction, we are effectively penalizing the model based on the size of\nthe coefficients.\n\n"
         ]
      },
      {
         "metadata" : {},
         "outputs" : [],
         "cell_type" : "code",
         "execution_count" : 1,
         "source" : [
            "from sklearn.linear_model import Lasso\nmodel = Lasso().fit( X, y )"
         ]
      },
      {
         "cell_type" : "markdown",
         "source" : [
            "Does this really change the coeffiicients at all?\n\n"
         ],
         "metadata" : {}
      },
      {
         "outputs" : [],
         "metadata" : {},
         "execution_count" : 1,
         "source" : [
            "model.coef_"
         ],
         "cell_type" : "code"
      },
      {
         "metadata" : {},
         "source" : [
            "Consider how important this could be, because not only does this make\nthe model &ldquo;simpler&rdquo; (perhaps avoiding overfitting?) but it also makes\nthe model more **explainable** in that we are identifying the key pieces\nof the input that explain the output.\n\nA part of data science involves creating models that you can actually\n&ldquo;sell&rdquo; in that someone else (who might know nothing of data) will\nbelieve the patterns you&rsquo;ve discovered.  As first noted by Hamming,\nthe purpose of computing is not numbers but **insight**.\n\n"
         ],
         "cell_type" : "markdown"
      }
   ],
   "nbformat_minor" : 0
}
