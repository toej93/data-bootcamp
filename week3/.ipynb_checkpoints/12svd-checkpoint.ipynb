{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing SVD with numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let&rsquo;s pick a matrix at random.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m = 6\n",
    "n = 5\n",
    "A = np.random.normal(0,1,size=(m,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $A$ is **not** square, so `np.linalg.eigvals` fails.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Last 2 dimensions of the array must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1f3b904a7357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36meigvals\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_makearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0m_assertRankAtLeast2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m     \u001b[0m_assertNdSquareness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0m_assertFinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_assertNdSquareness\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Last 2 dimensions of the array must be square'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assertFinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
     ]
    }
   ],
   "source": [
    "np.linalg.eigvals(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, we can compute the singular-value decomposition, usually\n",
    "known by the acronym SVD.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now $A$ is $m \\times n$, or in `numpy`&rsquo;s syntax, `A.shape == (m,n)`.\n",
    "\n",
    "Then $U$ is $m \\times m$, and $s$ has length $\\mathrm{min}(m,n)$, and\n",
    "$V$ is $n \\times n$.  Let&rsquo;s check this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape == (m,m) and len(s) == min(m,n) and V.shape == (n,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers in `s` are the **singular values** of $A$.  The columns of\n",
    "$U$ are the **left-singular vectors** and the columns of $V$ are the\n",
    "**right-singular vectors** of $A$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD is a matrix factorization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many &ldquo;matrix factorizations&rdquo; in the world.  SVD is such a\n",
    "factorization.  Let&rsquo;s see this in some specific case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.777435951140746e-15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "m = 6\n",
    "n = 5\n",
    "A = np.random.normal(0,1,size=(m,n))\n",
    "\n",
    "U, s, V = np.linalg.svd(A)\n",
    "\n",
    "S = np.zeros( (m, n) )\n",
    "S[:len(s), :len(s)] = np.diag(s)\n",
    "\n",
    "np.linalg.norm( U.dot(S.dot(V)) - A )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $A$ is (well, nearly &#x2013; we&rsquo;re working with floats after all!) the\n",
    "product $USV$ where $S$ is a matrix build from the singular values\n",
    "$s$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD as a \"numerical rank\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One application of SVD is as a more stable way to calculate rank.\n",
    "\n",
    "Let&rsquo;s build a low-rank matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m = 6\n",
    "n = 5\n",
    "r = 2\n",
    "X = np.random.normal(0,1,size=(m,r))\n",
    "Y = np.random.normal(0,1,size=(r,n))\n",
    "A = X.dot(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that this is indeed low-rank.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we add some noise to $A$, we might begin to worry.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.random.normal(0,0.01,size=(m,n))\n",
    "np.linalg.matrix_rank(A + noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rank of $A + \\mathrm{noise}$ is indeed $\\mathrm{min}(m,n)$.\n",
    "\n",
    "Look at the singular values though.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.96650791e+00, 2.55896638e+00, 2.11765002e-02, 1.28759937e-02,\n",
       "       3.58453327e-03])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, s, _ = np.linalg.svd(A + noise)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some large singular values, and some small singular values.\n",
    "Let&rsquo;s leverage this observation to compute rank even for noisy\n",
    "matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_rank(A, epsilon=0.1):\n",
    "   _, s, _ = np.linalg.svd(A + noise)\n",
    "   return np.sum( np.abs(s) > epsilon )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_rank(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD for the pseudoinverse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let&rsquo;s again pick a random matrix $A$ and finds its SVD.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m = 6\n",
    "n = 5\n",
    "A = np.random.normal(0,1,size=(m,n))\n",
    "\n",
    "U, s, V = np.linalg.svd(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now construct $A^{+}$, a **pseudoinverse** of $A$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -2.59455953e-16  2.88879462e-16  6.94022946e-16\n",
      "  -2.32118119e-16]\n",
      " [ 3.63860162e-17  1.00000000e+00  2.82942684e-16  1.73721031e-16\n",
      "  -2.75533859e-16]\n",
      " [ 1.05639479e-16 -6.34276628e-16  1.00000000e+00 -9.14873027e-17\n",
      "   4.56770791e-16]\n",
      " [-4.91269409e-17 -2.65885490e-16  2.40810068e-16  1.00000000e+00\n",
      "  -9.15085439e-18]\n",
      " [-9.63749730e-17 -1.16833061e-16  5.84043272e-17  1.09530665e-16\n",
      "   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "D = np.zeros( (n, m) )\n",
    "D[:len(s), :len(s)] = np.diag(1/s)\n",
    "\n",
    "Aplus = (V.T).dot( D.dot( U.T ) )\n",
    "print(Aplus.dot( A ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this ever the actual inverse of $A$?  When $A$ is not square, what\n",
    "are some nevertheless nice properties of the pseudoinverse?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD for dimension reduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a matrix $A$, we could ask for the &ldquo;nearest&rdquo; matrix to $A$ which\n",
    "has rank $r$.\n",
    "\n",
    "Your homework is to structure this as yet another &ldquo;cost&rdquo; problem,\n",
    "i.e., the cost to minimize is the sum of the squares of the difference\n",
    "of the entries of $A$ and the rank $r$ approximation.  Randomly sample to get a sense of the distribution of these cost functions.\n",
    "\n",
    "Then see how well you do with SVD; throw away all but the largest $r$\n",
    "singular values, replace the others with zero, and perform the same\n",
    "&ldquo;matrix reconstruction&rdquo; as above.  Of course, you won&rsquo;t get the\n",
    "original matrix, but what is the rank of the matrix you produced?  How\n",
    "close is it to the original matrix?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD to PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot more to say about the power of SVD.\n",
    "\n",
    "One thing to dig into is the relationship between SVD and PCA.  Some of this is discussed at [https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca](https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your comparative advantage in the marketplace lies in your ability to\n",
    "leverage your existing knowledge and apply it to data science.  With\n",
    "things like SVD, I hope you recognize just how strong you really are:\n",
    "you know a ton of mathematics, and you can use this to dig deeper &#x2013;\n",
    "and dig quickly &#x2013; into data science.  The intuition you have from\n",
    "linear algebra will serve you well throughout your career.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
