{
   "nbformat" : 4,
   "metadata" : {
      "language_info" : {
         "name" : "python",
         "nbconvert_exporter" : "python",
         "codemirror_mode" : {
            "version" : 3,
            "name" : "ipython"
         },
         "version" : "3.5.2",
         "pygments_lexer" : "ipython3",
         "file_extension" : ".py",
         "mimetype" : "text/x-python"
      },
      "org" : null,
      "kernelspec" : {
         "display_name" : "Python 3",
         "name" : "python3",
         "language" : "python"
      }
   },
   "nbformat_minor" : 0,
   "cells" : [
      {
         "source" : [
            "## Initialization\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "metadata" : {},
         "cell_type" : "markdown",
         "source" : [
            "Let&rsquo;s set up our environment.\n\n"
         ]
      },
      {
         "source" : [
            "import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('galton.csv')"
         ],
         "execution_count" : 1,
         "cell_type" : "code",
         "metadata" : {},
         "outputs" : []
      },
      {
         "source" : [
            "Let&rsquo;s extend `df` with midparent height.\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "execution_count" : 1,
         "source" : [
            "df['midparent'] = (df.father + df.mother)/2"
         ],
         "cell_type" : "code",
         "outputs" : [],
         "metadata" : {}
      },
      {
         "cell_type" : "markdown",
         "metadata" : {},
         "source" : [
            "## Linear regression\n\n"
         ]
      },
      {
         "source" : [
            "**Supervised learning** means learning the relationship between two sets\nof data: the observed data $X$ and an external variable $y$ that we\nare trying to predict.  Often $y$ is called the &ldquo;target&rdquo; (for\nregression) or &ldquo;labels&rdquo; (for classification).  Let&rsquo;s load some code\nfrom `scikit-learn` to perform linear regression.\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "outputs" : [],
         "metadata" : {},
         "cell_type" : "code",
         "source" : [
            "from sklearn.linear_model import LinearRegression"
         ],
         "execution_count" : 1
      },
      {
         "metadata" : {},
         "cell_type" : "markdown",
         "source" : [
            "Supervised estimators in `scikit-learn` (like `LinearRegression`)\nimplement a `fit` method to fit the model and a `predict` method that\nconverts observations into predicted targets or labels.\n\n"
         ]
      },
      {
         "execution_count" : 1,
         "source" : [
            "lm = LinearRegression().fit( df[['midparent']], df['height'] )"
         ],
         "outputs" : [],
         "metadata" : {},
         "cell_type" : "code"
      },
      {
         "metadata" : {},
         "cell_type" : "markdown",
         "source" : [
            "This provides a slope and intercept.\n\n"
         ]
      },
      {
         "cell_type" : "code",
         "outputs" : [],
         "metadata" : {},
         "source" : [
            "print('height = {m} * midparent + {b}'.format(m = lm.coef_[0], b = lm.intercept_))"
         ],
         "execution_count" : 1
      },
      {
         "source" : [
            "Let&rsquo;s plot it.\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "execution_count" : 1,
         "source" : [
            "df.plot.scatter('midparent', 'height')\nplt.plot( df['midparent'], lm.predict(df[['midparent']]), color='red', linewidth=3 )\nplt.show()"
         ],
         "cell_type" : "code",
         "outputs" : [],
         "metadata" : {}
      },
      {
         "metadata" : {},
         "cell_type" : "markdown",
         "source" : [
            "You could now consult [the documentation of\n~scikit-learn~]([https://scikit-learn.org/stable/modules/linear_model.html](https://scikit-learn.org/stable/modules/linear_model.html))\nto try fitting fancier models, perhaps using the heights of both\nparents.\n\n"
         ]
      },
      {
         "cell_type" : "markdown",
         "metadata" : {},
         "source" : [
            "## Is this any good?\n\n"
         ]
      },
      {
         "metadata" : {},
         "cell_type" : "markdown",
         "source" : [
            "By &ldquo;any good&rdquo; we mean: is our model valid?  To evaluate the\nperformance of the model, we would need to test it on some unseen\ndata&#x2026; but we aren&rsquo;t going to find children and their parents and\nmeasure their heights.\n\n****Cross-validation**** is a solution to the question of &ldquo;validity&rdquo; of\nthe model, and also a solution to our not having unseen data.  Instead\nof running `fit` on **all** the data, we keep aside some portion of the\ndata and use that &ldquo;hold-out&rdquo; data for validation.\n\nTo be more specific, there are various ways of arranging for this.  We\nmight **split the data into a training set and a testing set**. \n\nAnother method is **k-fold cross-validation** in which the original data\nis partitioned (randomly) into $k$ equal sized subsamples. Of the $k$\nsubsamples, a single subsample is retained as the validation data for\ntesting the model, and the remaining $k â 1$ subsamples are used as\ntraining data.  Conveniently, `scikit-learn` has methods for this.\n\n"
         ]
      },
      {
         "cell_type" : "code",
         "metadata" : {},
         "outputs" : [],
         "source" : [
            "from sklearn.model_selection import KFold"
         ],
         "execution_count" : 1
      },
      {
         "metadata" : {},
         "cell_type" : "markdown",
         "source" : [
            "Let&rsquo;s use it.\n\n"
         ]
      },
      {
         "source" : [
            "model = LinearRegression()\nscores = []\n\nX = df[['midparent']]\ny = df['height']\n\nkf = KFold(n_splits=5, shuffle=True, random_state=1)\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    model.fit(X_train, y_train)\n    score = model.score(X_test, y_test)\n    scores.append(score)\n\nscores"
         ],
         "execution_count" : 1,
         "cell_type" : "code",
         "outputs" : [],
         "metadata" : {}
      },
      {
         "source" : [
            "Those $R^2$ scores are not especially reassuring.  Can we do better?\nAre we missing something in our model?\n\n"
         ],
         "metadata" : {},
         "cell_type" : "markdown"
      }
   ]
}
